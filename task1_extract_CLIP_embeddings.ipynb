{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VClBXhovn6Tt"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orIuvY5kl7sU"
   },
   "outputs": [],
   "source": [
    "%pip install multilingual-clip torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCsAJmb0rAvH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmPWy95ol_Ve"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from multilingual_clip import pt_multilingual_clip\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image, ImageFile\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCkFSImzfA4E"
   },
   "source": [
    "#Extract CLIP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw_TMBKTo33U"
   },
   "outputs": [],
   "source": [
    "main_folder = \"/content/drive/MyDrive/SemEval2025/task1/\"\n",
    "\n",
    "clip_model_names = [('M-CLIP/XLM-Roberta-Large-Vit-L-14', \"clip-ViT-L-14\"),\n",
    "                    ('M-CLIP/XLM-Roberta-Large-Vit-B-32', \"clip-ViT-B-32\"),\n",
    "                    ('M-CLIP/LABSE-Vit-L-14', \"clip-ViT-L-14\")\n",
    "                    ]\n",
    "\n",
    "train_folders = [main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A Train/\",\n",
    "                 main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A PT Train/\",\n",
    "                 main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A Test/\",\n",
    "                 main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A PT Test/\",\n",
    "                 main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A Extended Evaluation/\",\n",
    "                 main_folder + \"dataset results gpt4-4o/AdMIRe Subtask A PT Extended Evaluation/\"]\n",
    "\n",
    "llm_names = [\"gpt-3.5\", \"gpt-4\", \"gpt-4o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNvD8zzZ7ogg"
   },
   "outputs": [],
   "source": [
    "def load_image(url_or_path):\n",
    "  return Image.open(url_or_path)\n",
    "\n",
    "def get_caption_embeddings(text_model, tokenizer, captions):\n",
    "  truncated_captions = []\n",
    "  for caption in captions:\n",
    "    tokens = tokenizer.encode(caption, max_length=512, truncation=True)\n",
    "    truncated_caption = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    truncated_captions.append(truncated_caption)\n",
    "\n",
    "  cap_embeddings = [text_model.forward(caption, tokenizer).detach().numpy().squeeze()  for caption in truncated_captions]\n",
    "  return cap_embeddings\n",
    "\n",
    "for clip_model_name in clip_model_names:\n",
    "  text_model_name  = clip_model_name[0]\n",
    "  img_model_name = clip_model_name[1]\n",
    "\n",
    "  text_model = pt_multilingual_clip.MultilingualCLIP.from_pretrained(text_model_name)\n",
    "  tokenizer = transformers.AutoTokenizer.from_pretrained(text_model_name)\n",
    "\n",
    "  img_model = SentenceTransformer(img_model_name)\n",
    "\n",
    "  for llm_name in llm_names:\n",
    "    for train_folder in train_folders:\n",
    "      if \"Train\" in train_folder:\n",
    "        train_df_file_path = train_folder + f\"subtask_a_train_{llm_name}_meanings.tsv\"\n",
    "      elif \"Test\" in train_folder:\n",
    "        train_df_file_path = train_folder + f\"subtask_a_test_{llm_name}_meanings.tsv\"\n",
    "      elif \"Dev\" in train_folder:\n",
    "        train_df_file_path = train_folder + f\"subtask_a_dev_{llm_name}_meanings.tsv\"\n",
    "      elif \"Extended\" in train_folder:\n",
    "        if \"PT\" in train_folder:\n",
    "          train_df_file_path = train_folder + f\"subtask_a_xp_{llm_name}_meanings.tsv\"\n",
    "        else:\n",
    "          train_df_file_path = train_folder + f\"subtask_a_xe_{llm_name}_meanings.tsv\"\n",
    "      else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "      #text_augment_bt_file_path = main_folder+ \"text_augment_train_A/output_back_translated.tsv\"\n",
    "      #text_augment_pr_file_path = main_folder+ \"text_augment_train_A/output_paraphrased.tsv\"\n",
    "      #image_augment_folder      = main_folder+ \"image_augment_train_A/augmented_train\"\n",
    "\n",
    "      text_augment_bt_file_path = None\n",
    "      text_augment_pr_file_path = None\n",
    "      image_augment_folder      = None\n",
    "\n",
    "      df = pd.read_csv(train_df_file_path, sep='\\t')\n",
    "\n",
    "      all_text_embeddings = []\n",
    "      all_img_embeddings = []\n",
    "      all_cap_embeddings = []\n",
    "      all_bt_cap_embeddings = []\n",
    "      all_pr_cap_embeddings = []\n",
    "      all_aug_img_embeddings = []\n",
    "\n",
    "      for _, row in df.iterrows():\n",
    "\n",
    "        #Get data\n",
    "        compound = row['compound']\n",
    "        img_names = []\n",
    "        captions = []\n",
    "        bt_captions = []\n",
    "        pr_captions = []\n",
    "        aug_img_names = []\n",
    "        for i in range(1,6):\n",
    "          image_name = row[f\"image{i}_name\"]\n",
    "          img_names.append(image_name)\n",
    "\n",
    "          caption = row[f\"image{i}_caption\"]\n",
    "          captions.append(caption)\n",
    "\n",
    "          if text_augment_bt_file_path is not None:\n",
    "            bt_caption = row[f\"image{i}_caption_bt\"]\n",
    "            bt_captions.append(bt_caption)\n",
    "\n",
    "          if text_augment_pr_file_path is not None:\n",
    "            pr_caption = row[f\"image{i}_caption_para\"]\n",
    "            pr_captions.append(pr_caption)\n",
    "\n",
    "          if image_augment_folder is not None:\n",
    "            aug_image_name = row[f\"image{i}_name\"].replace(\".png\", \"_aug1.png\")\n",
    "            aug_img_names.append(aug_image_name)\n",
    "\n",
    "        print(row['compound'], row[\"sent_type_predicted\"], row[\"sentence_type\"])\n",
    "\n",
    "        # Get text (compound) embedding\n",
    "        if row[\"sent_type_predicted\"] == 'literal':\n",
    "          text_embedding = text_model.forward(compound, tokenizer).detach().numpy()\n",
    "        elif row[\"sent_type_predicted\"] == 'idiomatic':\n",
    "          meaning = row[\"meaning\"]\n",
    "          text_embedding = text_model.forward(meaning, tokenizer).detach().numpy()\n",
    "        else:\n",
    "          raise NotImplementedError\n",
    "\n",
    "        # Get image embeddings\n",
    "        images     = [load_image(f\"\"\"{train_folder}/{compound.replace(\"'\", \"_\")}/{image_name}\"\"\") for image_name in img_names]\n",
    "        img_embeddings     = img_model.encode(images)\n",
    "\n",
    "        # Get caption embeddings\n",
    "        cap_embeddings    =  get_caption_embeddings(text_model, tokenizer, captions)\n",
    "\n",
    "        # Save embeddings\n",
    "        all_text_embeddings.append(text_embedding)\n",
    "        all_img_embeddings.append(np.array(img_embeddings))\n",
    "        all_cap_embeddings.append(np.array([cap_embedding.squeeze() for cap_embedding in cap_embeddings]))\n",
    "\n",
    "          # Get embedding of augmented data\n",
    "        if image_augment_folder is not None:\n",
    "          aug_images = [load_image(f\"\"\"{image_augment_folder}/{compound.replace(\"'\", \"_\")}/{image_name}\"\"\") for image_name in aug_img_names]\n",
    "          aug_img_embeddings = img_model.encode(aug_images)\n",
    "          all_aug_img_embeddings.append(np.array(aug_img_embeddings))\n",
    "\n",
    "        if text_augment_bt_file_path is not None:\n",
    "          bt_cap_embeddings =  get_caption_embeddings(text_model, tokenizer, bt_captions)\n",
    "          all_bt_cap_embeddings.append(np.array([bt_cap_embedding.squeeze() for bt_cap_embedding in bt_cap_embeddings]))\n",
    "\n",
    "        if text_augment_pr_file_path is not None:\n",
    "          pr_cap_embeddings =  get_caption_embeddings(text_model, tokenizer, pr_captions)\n",
    "          all_pr_cap_embeddings.append(np.array([pr_cap_embedding.squeeze() for pr_cap_embedding in pr_cap_embeddings]))\n",
    "\n",
    "\n",
    "      stacked_text_embeddings = np.vstack(all_text_embeddings)\n",
    "      stacked_img_embeddings = np.stack(all_img_embeddings)\n",
    "      stacked_cap_embeddings = np.stack(all_cap_embeddings)\n",
    "      print(\"Shape compound embeddings:\", stacked_text_embeddings.shape)\n",
    "      print(\"Shape image embeddings:\", stacked_img_embeddings.shape)\n",
    "      print(\"Shape caption embeddings:\", stacked_cap_embeddings.shape)\n",
    "      np.save(train_folder + f\"baseline_text_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_text_embeddings)\n",
    "      np.save(train_folder + f\"baseline_img_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_img_embeddings)\n",
    "      np.save(train_folder + f\"baseline_cap_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_cap_embeddings)\n",
    "\n",
    "      if text_augment_bt_file_path is not None:\n",
    "        stacked_bt_cap_embeddings = np.stack(all_bt_cap_embeddings)\n",
    "        print(\"Shape augmented caption (back-translated) embeddings:\", stacked_bt_cap_embeddings.shape)\n",
    "        np.save(train_folder + f\"bt_cap_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_bt_cap_embeddings)\n",
    "\n",
    "      if text_augment_pr_file_path is not None:\n",
    "        stacked_pr_cap_embeddings = np.stack(all_pr_cap_embeddings)\n",
    "        print(\"Shape augmented caption (paraphrased) embeddings:\", stacked_pr_cap_embeddings.shape)\n",
    "        np.save(train_folder + f\"pr_cap_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_pr_cap_embeddings)\n",
    "\n",
    "      if image_augment_folder is not None:\n",
    "        stacked_aug_img_embeddings = np.stack(all_aug_img_embeddings)\n",
    "        print(\"Shape augmented image embeddings:\", stacked_aug_img_embeddings.shape)\n",
    "        np.save(train_folder + f\"aug_img_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\", stacked_img_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YXE6ec5aat_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk4LhRHaqFLa"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
