{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeDRQAAqK-2E"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eh9Mw5dXppSK"
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Ensures deterministic behavior when using PyTorch's CUDA backend\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # Set a consistent seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXlTFXZ1ouqu"
   },
   "outputs": [],
   "source": [
    "llm_name = \"gpt-4o\"\n",
    "text_model_name = 'M-CLIP/LABSE-Vit-L-14'\n",
    "\n",
    "main_folder = \"/content/drive/MyDrive/SemEval2025/task1/\"\n",
    "\n",
    "train_folder = main_folder + \"/dataset results gpt4-4o/AdMIRe Subtask A Train/\"\n",
    "train_df_file_path = train_folder + f\"subtask_a_train_{llm_name}_meanings.tsv\"\n",
    "\n",
    "dev_folder = main_folder + \"/dataset results gpt4-4o/AdMIRe Subtask A Dev/\"\n",
    "dev_df_file_path = dev_folder + f\"subtask_a_dev_{llm_name}_meanings.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLec1MHiGHR-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo0A83U0FBzA",
    "outputId": "6d93e93f-7a59-4f53-9738-d06bd6ca4a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file: /content/drive/MyDrive/SemEval2025/task1//dataset results gpt4-4o/AdMIRe Subtask A Train/subtask_a_train_gpt-4o_meanings.tsv\n",
      "Size of training dataset: 70\n",
      "Text embeddings shape: (70, 768)\n",
      "Image embeddings shape: (70, 5, 768)\n",
      "Caption embeddings shape: (70, 5, 768)\n",
      "Aug Image embeddings shape: (70, 5, 768)\n",
      "BT Caption embeddings shape: (70, 5, 768)\n",
      "PR Caption embeddings shape: (70, 5, 768)\n",
      "\n",
      "Training size: 50\n",
      "Validation size: 6\n",
      "Test size: 14\n",
      "\n",
      "Training size: 50\n",
      "\tText embeddings size: (50, 768)\n",
      "\tImage embeddings size: (50, 5, 768)\n",
      "\tAugmented Image embeddings size: (50, 5, 768)\n",
      "\tCaption embeddings size: (50, 5, 768)\n",
      "\tBT Caption embeddings size: (50, 5, 768)\n",
      "\tPR Caption embeddings size: (50, 5, 768)\n",
      "\n",
      "Validation size: 6\n",
      "\tText embeddings size: (6, 768)\n",
      "\tImage embeddings size: (6, 5, 768)\n",
      "\tAugmented Image embeddings size: (6, 5, 768)\n",
      "\tCaption embeddings size: (6, 5, 768)\n",
      "\tBT Caption embeddings size: (6, 5, 768)\n",
      "\tPR Caption embeddings size: (6, 5, 768)\n",
      "\n",
      "Validation size: 14\n",
      "\tText embeddings size: (14, 768)\n",
      "\tImage embeddings size: (14, 5, 768)\n",
      "\tAugmented Image embeddings size: (14, 5, 768)\n",
      "\tCaption embeddings size: (14, 5, 768)\n",
      "\tBT Caption embeddings size: (14, 5, 768)\n",
      "\tPR Caption embeddings size: (14, 5, 768)\n",
      "16 0.0001 10 0.08 0.5\n",
      "Epoch [1/500], Train Loss: 1.0148, Val Loss: 3.6571, Test Acc: 0.2143, Test Corr: 0.0643\n",
      "✅ Model saved!\n",
      "Epoch [2/500], Train Loss: 0.9728, Val Loss: 3.4340, Test Acc: 0.3571, Test Corr: 0.0929\n",
      "✅ Model saved!\n",
      "Epoch [3/500], Train Loss: 0.9187, Val Loss: 3.3102, Test Acc: 0.4286, Test Corr: 0.0786\n",
      "✅ Model saved!\n",
      "Epoch [4/500], Train Loss: 0.8932, Val Loss: 3.2265, Test Acc: 0.4286, Test Corr: 0.1071\n",
      "✅ Model saved!\n",
      "Epoch [5/500], Train Loss: 0.8565, Val Loss: 3.1602, Test Acc: 0.5000, Test Corr: 0.1286\n",
      "✅ Model saved!\n",
      "Epoch [6/500], Train Loss: 0.8463, Val Loss: 3.1234, Test Acc: 0.5000, Test Corr: 0.0857\n",
      "✅ Model saved!\n",
      "Epoch [7/500], Train Loss: 0.8121, Val Loss: 3.1032, Test Acc: 0.5000, Test Corr: 0.0571\n",
      "✅ Model saved!\n",
      "Epoch [8/500], Train Loss: 0.8035, Val Loss: 3.0825, Test Acc: 0.5000, Test Corr: 0.0214\n",
      "✅ Model saved!\n",
      "Epoch [9/500], Train Loss: 0.7799, Val Loss: 3.0399, Test Acc: 0.5000, Test Corr: -0.0143\n",
      "✅ Model saved!\n",
      "Epoch [10/500], Train Loss: 0.7529, Val Loss: 2.9986, Test Acc: 0.4286, Test Corr: -0.0286\n",
      "✅ Model saved!\n",
      "Epoch [11/500], Train Loss: 0.7423, Val Loss: 2.9659, Test Acc: 0.5000, Test Corr: -0.0143\n",
      "✅ Model saved!\n",
      "Epoch [12/500], Train Loss: 0.6839, Val Loss: 2.9329, Test Acc: 0.5714, Test Corr: -0.0071\n",
      "✅ Model saved!\n",
      "Epoch [13/500], Train Loss: 0.6792, Val Loss: 2.9057, Test Acc: 0.5714, Test Corr: -0.0071\n",
      "✅ Model saved!\n",
      "Epoch [14/500], Train Loss: 0.6445, Val Loss: 2.9068, Test Acc: 0.5714, Test Corr: -0.0071\n",
      "Epoch [15/500], Train Loss: 0.6343, Val Loss: 2.9121, Test Acc: 0.5714, Test Corr: -0.0214\n",
      "Epoch [16/500], Train Loss: 0.5528, Val Loss: 2.9003, Test Acc: 0.5714, Test Corr: -0.0214\n",
      "✅ Model saved!\n",
      "Epoch [17/500], Train Loss: 0.5634, Val Loss: 2.9000, Test Acc: 0.5714, Test Corr: 0.0214\n",
      "✅ Model saved!\n",
      "Epoch [18/500], Train Loss: 0.5385, Val Loss: 2.8968, Test Acc: 0.5714, Test Corr: 0.0357\n",
      "✅ Model saved!\n",
      "Epoch [19/500], Train Loss: 0.5346, Val Loss: 2.8944, Test Acc: 0.5714, Test Corr: 0.0571\n",
      "✅ Model saved!\n",
      "Epoch [20/500], Train Loss: 0.4883, Val Loss: 2.9143, Test Acc: 0.5714, Test Corr: 0.0857\n",
      "Epoch [21/500], Train Loss: 0.5151, Val Loss: 2.9373, Test Acc: 0.5714, Test Corr: 0.0857\n",
      "Epoch [22/500], Train Loss: 0.4299, Val Loss: 2.9395, Test Acc: 0.5714, Test Corr: 0.0857\n",
      "Epoch [23/500], Train Loss: 0.4326, Val Loss: 2.9409, Test Acc: 0.5714, Test Corr: 0.1714\n",
      "Epoch [24/500], Train Loss: 0.4703, Val Loss: 2.9303, Test Acc: 0.5714, Test Corr: 0.1714\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. Prepare the Dataset\n",
    "# ================================\n",
    "def prepare_dataset(df, text_embeddings, img_embeddings, aug_img_embeddings, cap_embeddings, bt_cap_embeddings, pr_cap_embeddings, num_soft_negs=5):\n",
    "    anc_embeddings = []\n",
    "    pos_embeddings = []\n",
    "    neg_embeddings = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ground_truth = eval(row['expected_order'])\n",
    "        img_names = [row[f\"image{k}_name\"] for k in range(1, 6)]\n",
    "        sorted_indices = [img_names.index(gt) for gt in ground_truth]\n",
    "\n",
    "        # Prepare anchor-positive pairs\n",
    "        anc = text_embeddings[i, :]\n",
    "\n",
    "        pos_img = img_embeddings[i, sorted_indices[0], :]\n",
    "        pos_aug_img = aug_img_embeddings[i, sorted_indices[0], :]\n",
    "        pos_cap = cap_embeddings[i, sorted_indices[0], :]\n",
    "        pos_bt_cap = bt_cap_embeddings[i, sorted_indices[0], :]\n",
    "        pos_pr_cap = pr_cap_embeddings[i, sorted_indices[0], :]\n",
    "\n",
    "        # Prepare negatives based on the positive modality\n",
    "        hard_negs_img = []\n",
    "        hard_negs_aug_img = []\n",
    "        hard_negs_cap = []\n",
    "        hard_negs_bt_cap = []\n",
    "        hard_negs_pr_cap = []\n",
    "\n",
    "        for idx in range(5):\n",
    "            if idx != sorted_indices[0]:\n",
    "                # Negatives for image positive\n",
    "                hard_negs_img.append(img_embeddings[i, idx, :])\n",
    "                hard_negs_aug_img.append(aug_img_embeddings[i, idx, :])\n",
    "                hard_negs_cap.append(cap_embeddings[i, idx, :])\n",
    "                hard_negs_bt_cap.append(bt_cap_embeddings[i, idx, :])\n",
    "                hard_negs_pr_cap.append(pr_cap_embeddings[i, idx, :])\n",
    "\n",
    "        # Soft negatives from different rows\n",
    "        soft_negs_img = []\n",
    "        soft_negs_aug_img = []\n",
    "        soft_negs_cap = []\n",
    "        soft_negs_bt_cap = []\n",
    "        soft_negs_pr_cap = []\n",
    "\n",
    "        selected_rows = set()\n",
    "        count = 0\n",
    "        while count < num_soft_negs:\n",
    "            soft_neg_row = random.randint(0, len(df) - 1)\n",
    "            if soft_neg_row != i and soft_neg_row not in selected_rows:\n",
    "                selected_rows.add(soft_neg_row)\n",
    "\n",
    "                # Collect soft negatives from the same modality as the positive\n",
    "                for idx in range(5):\n",
    "                    soft_negs_img.append(img_embeddings[soft_neg_row, idx, :])\n",
    "                    soft_negs_aug_img.append(aug_img_embeddings[soft_neg_row, idx, :])\n",
    "                    soft_negs_cap.append(cap_embeddings[soft_neg_row, idx, :])\n",
    "                    soft_negs_bt_cap.append(bt_cap_embeddings[soft_neg_row, idx, :])\n",
    "                    soft_negs_pr_cap.append(pr_cap_embeddings[soft_neg_row, idx, :])\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        # Combine hard and soft negatives for each modality\n",
    "        all_negs_img = np.vstack(hard_negs_img + soft_negs_img)\n",
    "        all_negs_aug_img = np.vstack(hard_negs_aug_img + soft_negs_aug_img)\n",
    "        all_negs_cap = np.vstack(hard_negs_cap + soft_negs_cap)\n",
    "        all_negs_bt_cap = np.vstack(hard_negs_bt_cap + soft_negs_bt_cap)\n",
    "        all_negs_pr_cap = np.vstack(hard_negs_pr_cap + soft_negs_pr_cap)\n",
    "\n",
    "        # Append to dataset\n",
    "        anc_embeddings.append(anc)\n",
    "        pos_embeddings.append([pos_img, pos_aug_img, pos_cap, pos_bt_cap, pos_pr_cap])\n",
    "        neg_embeddings.append([all_negs_img, all_negs_aug_img, all_negs_cap, all_negs_bt_cap, all_negs_pr_cap])\n",
    "\n",
    "    return np.array(anc_embeddings), np.array(pos_embeddings), np.array(neg_embeddings)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 2. Dataset Class\n",
    "# ================================\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, anc_embeddings, pos_embeddings, neg_embeddings):\n",
    "        self.anc_embeddings = anc_embeddings\n",
    "        self.pos_embeddings = pos_embeddings\n",
    "        self.neg_embeddings = neg_embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anc_embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anc = torch.tensor(self.anc_embeddings[idx], dtype=torch.float32)\n",
    "\n",
    "        # List of positives for each modality (text-image, text-aug image, etc.)\n",
    "        pos = [torch.tensor(pos_emb, dtype=torch.float32) for pos_emb in self.pos_embeddings[idx]]\n",
    "\n",
    "        # List of negatives for each modality (text-image, text-aug image, etc.)\n",
    "        negs = [torch.tensor(neg_emb, dtype=torch.float32) for neg_emb in self.neg_embeddings[idx]]\n",
    "\n",
    "        return anc, pos, negs\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 3. Model Definition\n",
    "# ================================\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, projection_dim=768, dropout_rate=0.1):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, projection_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(projection_dim, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, anchor, positive, negatives):\n",
    "        # Project all embeddings to the same latent space\n",
    "        anchor_out = self.projection(anchor)\n",
    "        positive_out = [self.projection(p) for p in positive]\n",
    "        negative_outs = [self.projection(neg) for neg in negatives]  # negatives: [batch_size, num_negatives, embedding_dim]\n",
    "\n",
    "        # Normalize the outputs to the unit sphere\n",
    "        anchor_out = F.normalize(anchor_out, dim=-1)\n",
    "        positive_out = [F.normalize(p_out, dim=-1) for p_out in positive_out]\n",
    "        negative_outs = [F.normalize(neg_out, dim=-1) for neg_out in negative_outs]\n",
    "\n",
    "        return anchor_out, positive_out, negative_outs\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 4. Loss\n",
    "# ================================\n",
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(InfoNCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, anchor, positive, negatives):\n",
    "        # Normalize embeddings\n",
    "        anchor = F.normalize(anchor, p=2, dim=1)  # [Batch, Dim]\n",
    "        positive = [F.normalize(p, p=2, dim=1) for p in positive]  # [Batch, Dim] for each positive\n",
    "        negatives = [F.normalize(neg, p=2, dim=2) for neg in negatives]  # [Batch, num_negatives, Dim]\n",
    "\n",
    "        # Initialize loss\n",
    "        total_loss = 0\n",
    "\n",
    "        # Compute InfoNCE loss for each modality\n",
    "        for p, neg in zip(positive, negatives):\n",
    "            # Positive similarity\n",
    "            pos_sim = torch.exp(F.cosine_similarity(anchor, p) / self.temperature)  # [Batch]\n",
    "\n",
    "            # Negative similarities (per anchor for each modality)\n",
    "            neg_sim = torch.matmul(anchor.unsqueeze(1), neg.permute(0, 2, 1)).squeeze(1)  # [Batch, num_negatives]\n",
    "\n",
    "            # Apply temperature scaling to the negative similarities\n",
    "            neg_sim = torch.exp(neg_sim / self.temperature)  # [Batch, num_negatives]\n",
    "\n",
    "            # Compute the sum of negative similarities\n",
    "            neg_sim_sum = torch.sum(neg_sim, dim=1)  # [Batch]\n",
    "\n",
    "            # Compute InfoNCE loss using all negative samples for the modality\n",
    "            loss = -torch.log(pos_sim / (pos_sim + neg_sim_sum))\n",
    "\n",
    "            total_loss += loss.mean()\n",
    "\n",
    "        return total_loss / len(positive)  # Average loss over all modalities\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 5. Train the Model\n",
    "# ================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "            return False  # Continue training\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True  # Stop training\n",
    "        return False\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Training Phase\n",
    "        for anchor, positive, negatives in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out, positive_out, negative_outs = model(anchor, positive, negatives)\n",
    "            loss = criterion(anchor_out, positive_out, negative_outs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for anchor, positive, negatives in val_loader:\n",
    "                anchor_out, positive_out, negative_outs = model(anchor, positive, negatives)\n",
    "                loss = criterion(anchor_out, positive_out, negative_outs)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average losses\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "\n",
    "        top1_acc, avg_corr = evaluate_model(df_test, text_test, img_test, cap_test, model)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Test Acc: {top1_acc:.4f}, Test Corr: {avg_corr:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_contrastive_model.pth')\n",
    "            print(\"✅ Model saved!\")\n",
    "\n",
    "        results.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': lr,\n",
    "            'num_soft_negs': num_soft_negs,\n",
    "            'temperature': temperature,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'test_accuracy': top1_acc,\n",
    "            'test_corr': avg_corr\n",
    "        })\n",
    "\n",
    "        if early_stopping.step(val_loss):\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Function to predict the most similar images\n",
    "def predict(anchor_embedding, candidate_embeddings, model):\n",
    "    \"\"\"\n",
    "    Given an anchor text embedding and candidate image embeddings, predict the similarity scores.\n",
    "    \"\"\"\n",
    "    anchor_tensor = torch.tensor(anchor_embedding, dtype=torch.float32).unsqueeze(0)  # Shape: (1, embedding_dim)\n",
    "    candidate_tensors = torch.tensor(candidate_embeddings, dtype=torch.float32)        # Shape: (num_candidates, embedding_dim)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        anchor_out = model.projection(anchor_tensor)         # Shape: (1, embedding_dim)\n",
    "        candidate_outs = model.projection(candidate_tensors) # Shape: (num_candidates, embedding_dim)\n",
    "\n",
    "    similarities = torch.nn.functional.cosine_similarity(anchor_out, candidate_outs)  # Shape: (num_candidates,)\n",
    "    return similarities.tolist()\n",
    "\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(df_test, text_test, img_test, cap_test, model):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set using accuracy and Spearman's correlation.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    expected_orders = []\n",
    "    counts = []\n",
    "    correlations = []\n",
    "\n",
    "    for i, row in df_test.iterrows():\n",
    "        img_names = [row[f\"image{k}_name\"] for k in range(1, 6)]\n",
    "\n",
    "        # Get embeddings for the anchor and candidate images and predict similarities\n",
    "        anchor_embedding = text_test[i, :]\n",
    "        candidate_embeddings = img_test[i, :, :]\n",
    "        text_image_similarities = predict(anchor_embedding, candidate_embeddings, model)\n",
    "\n",
    "        # Get embeddings for the anchor and candidate captions and predict similarities\n",
    "        anchor_embedding = text_test[i, :]\n",
    "        candidate_embeddings = cap_test[i, :, :]\n",
    "        text_cap_similarities = predict(anchor_embedding, candidate_embeddings, model)\n",
    "\n",
    "        similarities = [a+b for a,b in zip(text_image_similarities, text_cap_similarities)]\n",
    "\n",
    "        sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "        # Sort the image names by predicted similarities\n",
    "        sorted_img_names = [img_names[k] for k in sorted_indices]\n",
    "\n",
    "        # Save the predicted order\n",
    "        expected_orders.append(str(sorted_img_names))\n",
    "\n",
    "        # Accuracy check: Top-1 match\n",
    "        if not any(df_test[\"expected_order\"].isna()):\n",
    "            ground_truth = eval(row['expected_order'])\n",
    "\n",
    "            # Top-1 accuracy\n",
    "            counts.append(1 if sorted_img_names[0] == ground_truth[0] else 0)\n",
    "\n",
    "            # Spearman's correlation\n",
    "            correlation, _ = spearmanr(sorted_img_names, ground_truth)\n",
    "            correlations.append(correlation)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    if counts:\n",
    "        top1_accuracy = sum(counts) / len(counts)\n",
    "        avg_spearman_corr = sum(correlations) / len(correlations)\n",
    "    else:\n",
    "        top1_accuracy = None\n",
    "        avg_spearman_corr = None\n",
    "\n",
    "    return top1_accuracy, avg_spearman_corr\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6. Main Pipeline\n",
    "# ================================\n",
    "\n",
    "# Load the training and development datasets\n",
    "train_df = pd.read_csv(train_df_file_path, sep='\\t')\n",
    "\n",
    "# Load the embeddings\n",
    "text_embeddings = np.load(train_folder + f\"training_text_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\")\n",
    "img_embeddings = np.load(train_folder + f\"training_img_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\")\n",
    "cap_embeddings = np.load(train_folder + f\"training_cap_embeddings_{llm_name}_{text_model_name.replace('/','-')}.npy\")\n",
    "aug_img_embeddings = np.load(train_folder + f\"aug_img_embeddings_gpt-3.5.npy\")\n",
    "bt_cap_embeddings = np.load(train_folder + f\"bt_cap_embeddings_gpt-3.5.npy\")\n",
    "pr_cap_embeddings = np.load(train_folder + f\"pr_cap_embeddings_gpt-3.5.npy\")\n",
    "\n",
    "# Print basic info\n",
    "print(\"Train file:\", train_df_file_path)\n",
    "print(\"Size of training dataset:\", len(train_df))\n",
    "print(\"Text embeddings shape:\", text_embeddings.shape)\n",
    "print(\"Image embeddings shape:\", img_embeddings.shape)\n",
    "print(\"Caption embeddings shape:\", cap_embeddings.shape)\n",
    "print(\"Aug Image embeddings shape:\", aug_img_embeddings.shape)\n",
    "print(\"BT Caption embeddings shape:\", bt_cap_embeddings.shape)\n",
    "print(\"PR Caption embeddings shape:\", pr_cap_embeddings.shape)\n",
    "\n",
    "# ================================\n",
    "# Split Train/Validation Set\n",
    "# ================================\n",
    "# First, split the dataset into Train+Val and Test sets\n",
    "df_train_val, df_test, text_train_val, text_test, img_train_val, img_test, aug_img_train_val, aug_img_test, cap_train_val, cap_test, bt_cap_train_val, bt_cap_test, pr_cap_train_val, pr_cap_test = train_test_split(\n",
    "    train_df, text_embeddings, img_embeddings, aug_img_embeddings, cap_embeddings, bt_cap_embeddings, pr_cap_embeddings,\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Then, split the Train+Val set into Train and Validation sets\n",
    "df_train, df_val, text_train, text_val, img_train, img_val, aug_img_train, aug_img_val, cap_train, cap_val, bt_cap_train, bt_cap_val, pr_cap_train, pr_cap_val = train_test_split(\n",
    "    df_train_val, text_train_val, img_train_val, aug_img_train_val, cap_train_val, bt_cap_train_val, pr_cap_train_val,\n",
    "    test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Reset the indices\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Print the sizes of each split\n",
    "print(\"\\nTraining size:\", len(df_train))\n",
    "print(\"Validation size:\", len(df_val))\n",
    "print(\"Test size:\", len(df_test))\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(\"\\nTraining size:\", len(df_train))\n",
    "print(\"\\tText embeddings size:\", text_train.shape)\n",
    "print(\"\\tImage embeddings size:\", img_train.shape)\n",
    "print(\"\\tAugmented Image embeddings size:\", aug_img_train.shape)\n",
    "print(\"\\tCaption embeddings size:\", cap_train.shape)\n",
    "print(\"\\tBT Caption embeddings size:\", bt_cap_train.shape)\n",
    "print(\"\\tPR Caption embeddings size:\", pr_cap_train.shape)\n",
    "\n",
    "print(\"\\nValidation size:\", len(df_val))\n",
    "print(\"\\tText embeddings size:\", text_val.shape)\n",
    "print(\"\\tImage embeddings size:\", img_val.shape)\n",
    "print(\"\\tAugmented Image embeddings size:\", aug_img_val.shape)\n",
    "print(\"\\tCaption embeddings size:\", cap_val.shape)\n",
    "print(\"\\tBT Caption embeddings size:\", bt_cap_val.shape)\n",
    "print(\"\\tPR Caption embeddings size:\", pr_cap_val.shape)\n",
    "\n",
    "\n",
    "print(\"\\nValidation size:\", len(df_test))\n",
    "print(\"\\tText embeddings size:\", text_test.shape)\n",
    "print(\"\\tImage embeddings size:\", img_test.shape)\n",
    "print(\"\\tAugmented Image embeddings size:\", aug_img_test.shape)\n",
    "print(\"\\tCaption embeddings size:\", cap_test.shape)\n",
    "print(\"\\tBT Caption embeddings size:\", bt_cap_test.shape)\n",
    "print(\"\\tPR Caption embeddings size:\", pr_cap_test.shape)\n",
    "\n",
    "param_grid = {\n",
    "    'batch_size': [16],\n",
    "    'learning_rate': [1e-4],\n",
    "    'num_soft_negs': [10],\n",
    "    'temperature': [0.08],\n",
    "    'dropout_rate' : [0.5]\n",
    "}\n",
    "\n",
    "param_combinations = itertools.product(param_grid['batch_size'],\n",
    "                                        param_grid['learning_rate'],\n",
    "                                        param_grid['num_soft_negs'],\n",
    "                                        param_grid['temperature'],\n",
    "                                        param_grid['dropout_rate'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch_size, lr, num_soft_negs, temperature, dropout_rate in param_combinations:\n",
    "\n",
    "  current_combination = (batch_size, lr, num_soft_negs, temperature, dropout_rate)\n",
    "\n",
    "  print(batch_size, lr, num_soft_negs, temperature, dropout_rate)\n",
    "\n",
    "  # Prepare train and validation datasets\n",
    "  anc_train, pos_train, neg_train = prepare_dataset(df_train, text_train, img_train, aug_img_train, cap_train, bt_cap_train,pr_cap_train, num_soft_negs=num_soft_negs)\n",
    "  anc_val, pos_val, neg_val       = prepare_dataset(df_val, text_val, img_val, aug_img_val, cap_val, bt_cap_val,pr_cap_val )\n",
    "\n",
    "  # ================================\n",
    "  # DataLoaders\n",
    "  # ================================\n",
    "  train_dataset = ContrastiveDataset(anc_train, pos_train, neg_train)\n",
    "  val_dataset = ContrastiveDataset(anc_val, pos_val, neg_val)\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  # ================================\n",
    "  # Initialize Model, Loss, and Optimizer\n",
    "  # ================================\n",
    "  embedding_dim = text_embeddings.shape[1]\n",
    "  model = ContrastiveModel(embedding_dim, projection_dim=768, dropout_rate=dropout_rate)\n",
    "\n",
    "  criterion = InfoNCELoss(temperature=temperature)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "  early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "  train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=500)\n",
    "\n",
    "  # Convert results to a dataframe\n",
    "  results_df = pd.DataFrame(results)\n",
    "\n",
    "  # Save the results to a CSV file\n",
    "  results_df.to_csv(main_folder + f'/training_results_{llm_name}_{text_model_name.replace(\"/\", \"-\")}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
